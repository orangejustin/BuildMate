# BuildMate: AI-Powered Construction Materials Assistant
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10-blue.svg)
![Node](https://img.shields.io/badge/node-16+-green.svg)
![LangChain](https://img.shields.io/badge/LangChain-0.1.0-orange.svg)

BuildMate is an intelligent AI assistant designed to help contractors and builders make informed decisions about construction materials. Leveraging advanced LLM technology and domain-specific knowledge, it provides real-time guidance on material selection, specifications, and best practices.

![BuildMate Demo](demo.png)

## ğŸš€ Key Features

- ğŸ¤– Context-aware material recommendations using RAG system
- ğŸ“Š Intelligent query classification and routing
- ğŸ—ï¸ Project planning and material quantity estimation
- ğŸ“‹ Technical specifications and compliance guidance
- ğŸ” Multi-turn conversation support
- âš¡ High-performance vector search
- ğŸ›¡ï¸ Robust error handling and edge case management

## ğŸ—ï¸ System Architecture

### Data Pipeline
```mermaid
graph LR
    A[Raw Data] --> B[Parser]
    B --> C[Structured JSON]
    C --> D[Metadata Extraction]
    D --> E[Vector Embeddings]
    E --> F[LanceDB Index]
```

### Chat Service Flow
```mermaid
graph TD
    A[User Query] --> B[Query Classification]
    B --> C[Context Enhancement]
    C --> D[RAG Retrieval]
    D --> E[LLM Processing]
    E --> F[Response Generation]
    F --> G[Memory Management]
```

## ğŸ› ï¸ Technical Implementation

### Backend Architecture
```
backend/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_data.txt              # Raw construction materials data
â”‚   â”œâ”€â”€ building_materials_docs.csv# Processed document store
â”‚   â”œâ”€â”€ clean_data.json           # Structured material data
â”‚   â””â”€â”€ parser.py                 # Data processing utilities
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ chat_service.py           # Core chat processing logic
â”‚   â””â”€â”€ query_classifier.py       # Query intent classification
â””â”€â”€ tests/
    â”œâ”€â”€ benchmark.py              # Performance testing
    â””â”€â”€ evaluate.py               # Quality metrics
```

### Frontend Structure
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx     # Main chat UI
â”‚   â”‚   â””â”€â”€ MaterialCard.jsx      # Material display component
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useChat.js           # Chat state management
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ api.js               # API integration
â””â”€â”€ public/
    â””â”€â”€ assets/                  # Static resources
```

## ğŸ”§ Technical Stack

### Backend
- **LLM Framework**: LangChain with GPT-4
- **Vector Store**: LanceDB with custom reranking
- **API**: FastAPI with async support
- **Embeddings**: OpenAI Ada-002
- **Testing**: pytest with custom benchmarking

### Frontend
- **Framework**: React 18 with Vite
- **Styling**: TailwindCSS
- **State Management**: React Context + Custom Hooks
- **API Client**: Axios with request interceptors

## ğŸ“¦ Installation

### Prerequisites
- Python 3.10+
- Node.js 16+
- pnpm
- OpenAI API key

### Backend Setup
```bash
# Create and activate environment
conda create -n buildmate python=3.10
conda activate buildmate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
touch .env
# Add your OpenAI API key (OPENAI_API_KEY) to .env
```

### Frontend Setup
```bash
# Install pnpm globally (recommended)
npm install -g pnpm # Or use npm if preferred

# Install base dependencies
pnpm install

# Install Tailwind CSS and its peer dependencies
pnpm install -D tailwindcss postcss autoprefixer
npx tailwindcss init -p

# Install utility libraries
pnpm install axios dayjs classnames
```

## ğŸš€ Development

### Running the Application
```bash
# Start backend
cd backend
uvicorn main:app --reload --port 8000

# Start frontend
cd frontend
pnpm dev
```

### Running Tests
```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
pnpm test
```

## ğŸ¯ Core Features Implementation

### RAG System
- Custom document chunking strategy
- Hybrid search with semantic and keyword matching
- Dynamic context window management
- Automated metadata extraction

### Query Processing
- Intent classification using fine-tuned model
- Context-aware prompt engineering
- Multi-turn conversation tracking
- Dynamic response templating

### Performance Optimization
- Async query processing
- Batched vector operations
- Response caching
- Rate limiting and queue management

## ğŸ“Š Performance Metrics

- Average response time: <2s
- RAG retrieval accuracy: >85%
- Query classification accuracy: >90%
- Memory usage: <512MB

## ğŸ”’ Security Considerations

- Input sanitization
- Rate limiting
- API key rotation
- Data encryption at rest
- CORS configuration
- Request validation

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch


## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI for GPT models
- LangChain community
- Construction industry experts who provided domain knowledge

## ğŸ“§ Support

For support and queries, please open an issue in the GitHub repository or contact the maintainers.